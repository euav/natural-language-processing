{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character CNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "oSRee2EcvTIa",
        "ABfd_fdcvTIj"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hcEul10vTHX",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies\n",
        "Let's download and import all the needed libraries.\n",
        "- **NumPy** is needed for intermidiate computaions,\n",
        "- **Pandas** is needed to store data,\n",
        "- **Python's RE** is needed for text preprocessing,\n",
        "- **lxml** is needed to parse data files stored in XML format,\n",
        "- **Scikit-learn** is needed to evaluate F1 score,\n",
        "- **MXNet** is choosed as deep learning framework,\n",
        "- **google.colab.drive** is need to mount Google Drive with all the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m98pnIouvcWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw-DXmVMvTHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import lxml.etree\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import mxnet as mx\n",
        "import mxnet.ndarray as nd\n",
        "import mxnet.gluon as gluon\n",
        "import mxnet.autograd as autograd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC4gKw3wDR5L",
        "colab_type": "code",
        "outputId": "b542e5e1-ccda-4453-fd14-89f2fdb2dada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "DRIVE_PATH = '/content/gdrive/My Drive/NLP Data/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "ujUsZYOPvTHl",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading\n",
        "Data should by extracted from XML files: tweets and their sentiments.\n",
        "And then before we can apply any algorithm data should be normalized.\n",
        "\n",
        "**Tweets normalization**\n",
        "- delete URLs\n",
        "- delete user tags\n",
        "- delete non-russian letters\n",
        "\n",
        "**Sentiments normalization**\n",
        "\n",
        "In data provided sentiments is given company wise, so it is need to assign sentiment on corresponding company to the whole tweet. In case of multiple different sentiments the given tweet will be assumed as sum of all sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qur30qQvTHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_tweet(string):\n",
        "    string = re.sub(r'(?:http[^\\s]+)($|\\s)', '', string)\n",
        "    string = re.sub(r'(?:@[^\\s]+)($|\\s)', '', string)\n",
        "    string = re.sub(r'[^абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ0123456789()!?\\- ]', '', string)\n",
        "    return string\n",
        "\n",
        "def normalize_sentiment(raw_sentiments_on_companies):\n",
        "    sentiment = 0\n",
        "    for raw_value in raw_sentiments_on_companies:\n",
        "        if raw_value.text != 'NULL':\n",
        "            sentiment += int(raw_value.text)\n",
        "    return np.sign(sentiment)\n",
        "\n",
        "def load_dataframe(filename, n_companies):\n",
        "    tweets = []\n",
        "    sentiments = []\n",
        "    \n",
        "    for sample in lxml.etree.parse(filename).xpath('database/table'):\n",
        "        tweet = normalize_tweet(sample[3].text)\n",
        "        sentiment = normalize_sentiment(sample[4:4+n_companies])\n",
        "\n",
        "        tweets.append(tweet)\n",
        "        sentiments.append(sentiment)\n",
        "    \n",
        "    return pd.DataFrame({'tweet': tweets, 'sent': sentiments})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hCvi5zvTHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bank_train = load_dataframe(DRIVE_PATH + 'SentiRuEval/bank_train_2016.xml', n_companies=8)\n",
        "bank_test = load_dataframe(DRIVE_PATH + 'SentiRuEval/bank_test_etalon.xml', n_companies=8)\n",
        "\n",
        "comm_train = load_dataframe(DRIVE_PATH + 'SentiRuEval/tkk_train_2016.xml', n_companies=7)\n",
        "comm_test = load_dataframe(DRIVE_PATH + 'SentiRuEval/tkk_test_etalon.xml', n_companies=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSt-4w1jvTH0",
        "colab_type": "text"
      },
      "source": [
        "Let's see the data we are working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv66swvOFGz1",
        "colab_type": "code",
        "outputId": "0b3ea1d5-f2fc-4fde-e4f9-54cdce578a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "bank_train.head(20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Взять кредит тюмень альфа банк</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Мнение о кредитной карте втб 24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Райффайзенбанк Снижение ключевой ставки ЦБ на ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Современное состояние кредитного поведения в р...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Главное чтоб банки СБЕР и ВТБ!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Оформить краткосрочный кредит оао банк москвы</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Самый выгодный автокредит в втб 24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Кредит иногородним в москве сбербанк</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Кредитный калькулятор россельхозбанк чита</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Легко можно получить денежный кредит ы втб 24 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ДЕЛО -  На 1 млрд грн ушел в минус Райффайзен ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Део нексия в кредит в альфа банке</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Россельхозбанк кредит стань фермером</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Банк втб взять кредит 40000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>обязательно про сбербанк напишите! Временами п...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Расчитать кредит сбер банк россии в москве</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Кредит в газпром банке тула</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Кредитный калькулятор сбербанк россии</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>втб и сбер точно вопрос-блокировка операций ил...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Взять кредит строительство магазина россельхоз...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                tweet  sent\n",
              "0                      Взять кредит тюмень альфа банк     0\n",
              "1                    Мнение о кредитной карте втб 24      0\n",
              "2   Райффайзенбанк Снижение ключевой ставки ЦБ на ...     0\n",
              "3   Современное состояние кредитного поведения в р...     0\n",
              "4                    Главное чтоб банки СБЕР и ВТБ!!!     1\n",
              "5       Оформить краткосрочный кредит оао банк москвы     0\n",
              "6                 Самый выгодный автокредит в втб 24      1\n",
              "7               Кредит иногородним в москве сбербанк      0\n",
              "8          Кредитный калькулятор россельхозбанк чита      0\n",
              "9   Легко можно получить денежный кредит ы втб 24 ...     1\n",
              "10  ДЕЛО -  На 1 млрд грн ушел в минус Райффайзен ...    -1\n",
              "11                 Део нексия в кредит в альфа банке      0\n",
              "12              Россельхозбанк кредит стань фермером      0\n",
              "13                        Банк втб взять кредит 40000     0\n",
              "14  обязательно про сбербанк напишите! Временами п...    -1\n",
              "15        Расчитать кредит сбер банк россии в москве      0\n",
              "16                       Кредит в газпром банке тула      0\n",
              "17             Кредитный калькулятор сбербанк россии      0\n",
              "18  втб и сбер точно вопрос-блокировка операций ил...    -1\n",
              "19  Взять кредит строительство магазина россельхоз...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1X78Z8XvTIB",
        "colab_type": "text"
      },
      "source": [
        "# Character CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7eM7v-uvTIC",
        "colab_type": "text"
      },
      "source": [
        "### Text quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6HA-h5cvTID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TWEET_MAX_LENGTH = 140\n",
        "CHARS = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ0123456789()!?- '\n",
        "CHARS = np.array(list(CHARS))\n",
        "\n",
        "def one_hot_by_letters(tweet):\n",
        "    padded_tweet = tweet + '~' * np.max(TWEET_MAX_LENGTH - len(tweet), 0)\n",
        "    padded_tweet = padded_tweet[0:TWEET_MAX_LENGTH]\n",
        "    tweet_as_array = np.array(list(padded_tweet))\n",
        "    return (CHARS[:,np.newaxis] == tweet_as_array[np.newaxis,:]).astype(np.float32)\n",
        "\n",
        "def one_hot_label(sentiment):\n",
        "    return (np.arange(3) == (sentiment + 1)).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAbvaIIYvTIG",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data for charcter-level CNN\n",
        "Here we can choose dataset for our investigation:\n",
        "1. Tweets about banks,\n",
        "2. Tweets about telecommunication companies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKdyX2HKIzlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframes = [bank_train, bank_test]\n",
        "#dataframes = [comm_train, comm_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefZqYsVvTIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = nd.zeros((len(dataframes[0]), len(CHARS), TWEET_MAX_LENGTH))\n",
        "y_train = nd.zeros((len(dataframes[0]), 3))\n",
        "                        \n",
        "X_test = nd.zeros((len(dataframes[1]), len(CHARS), TWEET_MAX_LENGTH))\n",
        "y_test = nd.zeros((len(dataframes[1]), 3))\n",
        "\n",
        "for i in range(len(bank_train)):\n",
        "    X_train[i] = one_hot_by_letters(dataframes[0].tweet[i])\n",
        "    y_train[i] = one_hot_label(dataframes[0].sent[i])\n",
        "    \n",
        "for i in range(len(bank_test)):\n",
        "    X_test[i] = one_hot_by_letters(dataframes[1].tweet[i])\n",
        "    y_test[i] = one_hot_label(dataframes[1].sent[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re_0_am0vTIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = gluon.data.ArrayDataset(X_train, y_train)\n",
        "test_dataset = gluon.data.ArrayDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = gluon.data.DataLoader(train_dataset, batch_size=1024, shuffle=False)\n",
        "test_dataloader = gluon.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4SuZInvTIL",
        "colab_type": "text"
      },
      "source": [
        "### Network configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqxpjIQLvTIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = gluon.nn.HybridSequential()\n",
        "with net.name_scope():\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=7, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3))\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=7, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3))\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=256, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3))\n",
        "    net.add(gluon.nn.Flatten())\n",
        "    net.add(gluon.nn.Dense(units=1024, activation='relu'))\n",
        "    net.add(gluon.nn.Dropout(0.5))\n",
        "    net.add(gluon.nn.Dense(units=1024, activation='relu'))\n",
        "    net.add(gluon.nn.Dropout(0.5))\n",
        "    net.add(gluon.nn.Dense(units=3))\n",
        "\n",
        "net.hybridize()\n",
        "softmax = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVa-2GJovTIO",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avz7HJjvTIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.initialize(mx.init.Normal(sigma=0.05), force_reinit=True, ctx=mx.gpu())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': 1e-4})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuslHEqtvTIQ",
        "colab_type": "code",
        "outputId": "ba3cdee0-c2d9-4b4c-fd42-432fe2acbf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "net.collect_params().reset_ctx(mx.gpu())\n",
        "for epoch in range(200):\n",
        "    accumulated_loss = 0\n",
        "    for features, label in train_dataloader:\n",
        "        features = features.as_in_context(mx.gpu())\n",
        "        label = label.as_in_context(mx.gpu())\n",
        "        with autograd.record(train_mode=True):\n",
        "            output = net(features)\n",
        "            loss = softmax(output, label)\n",
        "        loss.backward()\n",
        "        accumulated_loss += nd.mean(loss).asscalar()\n",
        "        trainer.step(batch_size=len(label))\n",
        "  \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('epoch', epoch + 1, '-- train loss', accumulated_loss / len(train_dataloader))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10 -- train loss 0.5998935788869858\n",
            "epoch 20 -- train loss 0.40318554937839507\n",
            "epoch 30 -- train loss 0.19931847974658012\n",
            "epoch 40 -- train loss 0.09152067825198174\n",
            "epoch 50 -- train loss 0.06047657029703259\n",
            "epoch 60 -- train loss 0.21127912104129792\n",
            "epoch 70 -- train loss 0.013271485595032573\n",
            "epoch 80 -- train loss 0.008066454855725168\n",
            "epoch 90 -- train loss 0.0054689147509634495\n",
            "epoch 100 -- train loss 0.004935975081752986\n",
            "epoch 110 -- train loss 0.004122918611392379\n",
            "epoch 120 -- train loss 0.0028939835727214815\n",
            "epoch 130 -- train loss 0.003715270553948358\n",
            "epoch 140 -- train loss 0.004006528505124151\n",
            "epoch 150 -- train loss 0.0023377157951472325\n",
            "epoch 160 -- train loss 0.003948430751916021\n",
            "epoch 170 -- train loss 0.0032697880611522122\n",
            "epoch 180 -- train loss 0.0033823663368821146\n",
            "epoch 190 -- train loss 0.003247474985255394\n",
            "epoch 200 -- train loss 0.0028242381958989426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBPdqol3vTIU",
        "colab_type": "text"
      },
      "source": [
        "### Testing\n",
        "For testing we will use only positive and negative tweets ignoring neutral ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35vBJOlDvTIU",
        "colab_type": "code",
        "outputId": "253328da-9485-4401-a95a-f5f765c00571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "net.collect_params().reset_ctx(mx.cpu())\n",
        "y_true = nd.argmax(y_test, axis=1).asnumpy()\n",
        "y_pred = nd.argmax(net(X_test), axis=1).asnumpy()\n",
        "\n",
        "mask = np.logical_or(y_true == 0, y_true == 2)\n",
        "\n",
        "accuracy = np.mean(y_true[mask] == y_pred[mask])\n",
        "f1_macro = f1_score(y_true[mask], y_pred[mask], average='macro', labels=(0,2))\n",
        "f1_micro = f1_score(y_true[mask], y_pred[mask], average='micro', labels=(0,2))\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1-macro:', f1_macro)\n",
        "print('F1-micro:', f1_micro)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.31115276476101217\n",
            "F1-macro: 0.3620841136369086\n",
            "F1-micro: 0.4328552803129074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzXPGYmZ_IAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}